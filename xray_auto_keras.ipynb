{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "441f493a-7d8c-4787-9d23-1ea838ed1609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-29 19:37:58.726832: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-01-29 19:37:58.726859: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import autokeras as ak\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f36be4ab-3a93-49bf-93b3-b46f6107df92",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_path = 'dataset/COVID-19_Radiography_Dataset/COVID'\n",
    "noncovid_path = 'dataset/COVID-19_Radiography_Dataset/Normal'\n",
    "\n",
    "covid_files = glob(covid_path + '/*')\n",
    "noncovid_files = glob(noncovid_path + '/*')\n",
    "\n",
    "covid_files = covid_files[:500]\n",
    "noncovid_files = noncovid_files[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "749506af-33ed-4a9c-9bcb-1df3440362eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensions\n",
    "import cv2\n",
    "\n",
    "covid_images = []\n",
    "covid_labels = []\n",
    "\n",
    "noncovid_images = []\n",
    "noncovid_labels = []\n",
    "\n",
    "for i in range(len(covid_files)):\n",
    "  image = cv2.imread(covid_files[i])\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  image = cv2.resize(image,(299,299))\n",
    "  covid_images.append(image)\n",
    "  covid_labels.append('Chest_COVID')\n",
    "  \n",
    "for i in range(len(noncovid_files)):\n",
    "  image = cv2.imread(noncovid_files[i])\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  image = cv2.resize(image,(299,299))\n",
    "  noncovid_images.append(image)\n",
    "  noncovid_labels.append('Chest_NonCOVID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "736e20f0-a85e-4a1d-904b-f616b0c9a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_images = np.array(covid_images) / 255\n",
    "noncovid_images = np.array(noncovid_images) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce0a2d4-5b43-43a5-8959-0b6e05ba922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing\n",
    "covid_x_train, covid_x_test, covid_y_train, covid_y_test = train_test_split(covid_images, covid_labels, test_size=0.2)\n",
    "noncovid_x_train, noncovid_x_test, noncovid_y_train, noncovid_y_test = train_test_split(noncovid_images, noncovid_labels, test_size=0.2)\n",
    "\n",
    "\n",
    "X_train = np.concatenate((noncovid_x_train, covid_x_train), axis=0)\n",
    "X_test = np.concatenate((noncovid_x_test, covid_x_test), axis=0)\n",
    "y_train = np.concatenate((noncovid_y_train, covid_y_train), axis=0)\n",
    "y_test = np.concatenate((noncovid_y_test, covid_y_test), axis=0)\n",
    "\n",
    "# make labels into categories - either 0 or 1\n",
    "y_train = LabelBinarizer().fit_transform(y_train)\n",
    "#y_train = to_categorical(y_train)\n",
    "\n",
    "y_test = LabelBinarizer().fit_transform(y_test)\n",
    "#y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f695aad0-84fd-4dc2-95a3-c623fa9bdddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 299, 299, 3), (200, 299, 299, 3), (800, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87550387-b510-4c31-8606-1dbbde9bef9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab6076c0-3bc9-424c-92c3-f51da78c671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ak.ImageClassifier(overwrite=True, max_trials=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb18c13d-6ca3-4205-9fb6-647abaf6d488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 13m 24s]\n",
      "val_loss: 3.661316938519121e-08\n",
      "\n",
      "Best val_loss So Far: 3.661316938519121e-08\n",
      "Total elapsed time: 00h 13m 24s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/50\n",
      "25/25 [==============================] - 78s 3s/step - loss: 62.4533 - accuracy: 0.7088\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 76s 3s/step - loss: 3.7225 - accuracy: 0.2087\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 76s 3s/step - loss: 0.7049 - accuracy: 0.2438\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 76s 3s/step - loss: 0.6985 - accuracy: 0.4313\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 76s 3s/step - loss: 0.6969 - accuracy: 0.2962\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 76s 3s/step - loss: 0.6938 - accuracy: 0.5763\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 76s 3s/step - loss: 0.6803 - accuracy: 0.5250\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 76s 3s/step - loss: 0.7563 - accuracy: 0.4750\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 76s 3s/step - loss: 0.6903 - accuracy: 0.5575\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 76s 3s/step - loss: 0.6887 - accuracy: 0.5412\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 76s 3s/step - loss: 0.6803 - accuracy: 0.6550\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 77s 3s/step - loss: 0.6623 - accuracy: 0.6475\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 78s 3s/step - loss: 0.6317 - accuracy: 0.7875\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 81s 3s/step - loss: 0.5965 - accuracy: 0.7287\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 85s 3s/step - loss: 0.6003 - accuracy: 0.7275\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 80s 3s/step - loss: 0.4972 - accuracy: 0.7688\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 80s 3s/step - loss: 0.4874 - accuracy: 0.8012\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 82s 3s/step - loss: 0.3968 - accuracy: 0.8263\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 84s 3s/step - loss: 0.3385 - accuracy: 0.8625\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 81s 3s/step - loss: 0.2815 - accuracy: 0.8988\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 81s 3s/step - loss: 0.2646 - accuracy: 0.8975\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 83s 3s/step - loss: 0.1935 - accuracy: 0.9350\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 83s 3s/step - loss: 0.1644 - accuracy: 0.9475\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 82s 3s/step - loss: 0.1247 - accuracy: 0.9775\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 82s 3s/step - loss: 0.1044 - accuracy: 0.9787\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 80s 3s/step - loss: 0.0769 - accuracy: 0.9875\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 79s 3s/step - loss: 0.0660 - accuracy: 0.9862\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 78s 3s/step - loss: 0.0496 - accuracy: 0.9912\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 82s 3s/step - loss: 0.0346 - accuracy: 0.9987\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 82s 3s/step - loss: 0.0256 - accuracy: 0.9987\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 83s 3s/step - loss: 0.0345 - accuracy: 0.9962\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 81s 3s/step - loss: 0.0180 - accuracy: 0.9987\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 82s 3s/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 83s 3s/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 84s 3s/step - loss: 0.0158 - accuracy: 0.9987\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 85s 3s/step - loss: 0.0164 - accuracy: 0.9987\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 83s 3s/step - loss: 0.0136 - accuracy: 0.9962\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 82s 3s/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 83s 3s/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 82s 3s/step - loss: 0.0078 - accuracy: 0.9987\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 80s 3s/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 86s 3s/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 82s 3s/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 85s 3s/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 83s 3s/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 84s 3s/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 83s 3s/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 86s 3s/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 84s 3s/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 83s 3s/step - loss: 0.0016 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-29 21:02:40.952387: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./image_classifier/best_model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f640c3ee850>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30772ff1-d2f6-4269-a3e0-6734bccd62c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.export_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdbc81a3-29e0-4673-92d4-0ac4f47f16d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.engine.functional.Functional"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "195f2eda-6175-441e-ae46-cead5d9d4f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: covid_classifier/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('covid_classifier', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdc03755-803e-4ea5-8729-e5691649ccfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 5s 571ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted_y = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67cf3b9f-632b-490c-abe1-066c337133d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80       100\n",
      "           1       0.81      0.78      0.80       100\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.80      0.80      0.80       200\n",
      "weighted avg       0.80      0.80      0.80       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70c7b189-fd69-4b18-adb9-26d3dec9fa89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 5s 492ms/step - loss: 0.9187 - accuracy: 0.8000\n",
      "[0.9186539649963379, 0.800000011920929]\n"
     ]
    }
   ],
   "source": [
    "print(clf.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dbf7dde-2c84-4d0c-a443-0ec27c1fa578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 299, 299, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63282a55-c97c-44ed-a8b1-2d17046f3260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 299, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8023c6-c79f-4327-890e-2e2b15f160e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
